{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "remarkable-salem",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The purpose of this workbook is to explore how to handle inconsistent data entry, meaning, handling values that are entered but not in a consistent manner. It will use sequence pattern matching to help isolate similar values so one can then clean them as needed.\n",
    "\n",
    "It is based on Lesson 5 of the Kaggle Data Cleaning course\n",
    "https://www.kaggle.com/alexisbcook/inconsistent-data-entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-theta",
   "metadata": {},
   "source": [
    "## FuzzyWuzzy\n",
    "\n",
    "The string matching FuzzyWuzzy library can give a score out of 100 to denote the similarity between strings. The higher the score, the higher the similarity. \n",
    "\n",
    "It was first developed to find and list event tickets off the internet. FuzzyWuzzy depends on the difflib library and Levenshtein distance to calculate the difference between patterns.\n",
    "\n",
    "For more on approximate string matching, the FuzzyWuzzy and difflib libraries:\n",
    "- https://en.wikipedia.org/wiki/Approximate_string_matching\n",
    "- https://stackoverflow.com/questions/31806695/when-to-use-which-fuzz-function-to-compare-2-strings\n",
    "- https://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
    "- https://docs.python.org/3/library/difflib.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-store",
   "metadata": {},
   "source": [
    "## Pakistan Intellectual Capital dataset\n",
    "\n",
    "I found the dataset and info at:\n",
    "https://www.kaggle.com/alexisbcook/pakistan-intellectual-capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regional-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas to read csv file\n",
    "import pandas as pd\n",
    "\n",
    "# see conclusion for more on this library\n",
    "import chardet\n",
    "\n",
    "# read in all our data\n",
    "professors = pd.read_csv(\"pakistan_intellectual_capital.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alleged-genome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S#</th>\n",
       "      <th>Teacher Name</th>\n",
       "      <th>University Currently Teaching</th>\n",
       "      <th>Department</th>\n",
       "      <th>Province University Located</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Terminal Degree</th>\n",
       "      <th>Graduated from</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Area of Specialization/Research Interests</th>\n",
       "      <th>Other Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Dr. Abdul Basit</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Engineering &amp; DBMS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Dr. Waheed Noor</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DBMS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Dr. Junaid Baber</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information processing, Multimedia mining</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Dr. Maheen Bakhtyar</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NLP, Information Retrieval, Question Answering...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>Samina Azim</td>\n",
       "      <td>Sardar Bahadur Khan Women's University</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Lecturer</td>\n",
       "      <td>BS</td>\n",
       "      <td>Balochistan University of Information Technolo...</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>VLSI Electronics DLD Database</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  S#         Teacher Name  \\\n",
       "0           2   3      Dr. Abdul Basit   \n",
       "1           4   5      Dr. Waheed Noor   \n",
       "2           5   6     Dr. Junaid Baber   \n",
       "3           6   7  Dr. Maheen Bakhtyar   \n",
       "4          24  25          Samina Azim   \n",
       "\n",
       "            University Currently Teaching             Department  \\\n",
       "0               University of Balochistan  Computer Science & IT   \n",
       "1               University of Balochistan  Computer Science & IT   \n",
       "2               University of Balochistan  Computer Science & IT   \n",
       "3               University of Balochistan  Computer Science & IT   \n",
       "4  Sardar Bahadur Khan Women's University       Computer Science   \n",
       "\n",
       "  Province University Located          Designation Terminal Degree  \\\n",
       "0                 Balochistan  Assistant Professor             PhD   \n",
       "1                 Balochistan  Assistant Professor             PhD   \n",
       "2                 Balochistan  Assistant Professor             PhD   \n",
       "3                 Balochistan  Assistant Professor             PhD   \n",
       "4                 Balochistan             Lecturer              BS   \n",
       "\n",
       "                                      Graduated from   Country    Year  \\\n",
       "0                      Asian Institute of Technology  Thailand     NaN   \n",
       "1                      Asian Institute of Technology  Thailand     NaN   \n",
       "2                      Asian Institute of Technology  Thailand     NaN   \n",
       "3                      Asian Institute of Technology  Thailand     NaN   \n",
       "4  Balochistan University of Information Technolo...  Pakistan  2005.0   \n",
       "\n",
       "           Area of Specialization/Research Interests Other Information  \n",
       "0                        Software Engineering & DBMS               NaN  \n",
       "1                                               DBMS               NaN  \n",
       "2          Information processing, Multimedia mining               NaN  \n",
       "3  NLP, Information Retrieval, Question Answering...               NaN  \n",
       "4                      VLSI Electronics DLD Database               NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sudden-buyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1142 entries, 0 to 1141\n",
      "Data columns (total 13 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   Unnamed: 0                                 1142 non-null   int64  \n",
      " 1   S#                                         1142 non-null   int64  \n",
      " 2   Teacher Name                               1142 non-null   object \n",
      " 3   University Currently Teaching              1142 non-null   object \n",
      " 4   Department                                 1142 non-null   object \n",
      " 5   Province University Located                1142 non-null   object \n",
      " 6   Designation                                1123 non-null   object \n",
      " 7   Terminal Degree                            1138 non-null   object \n",
      " 8   Graduated from                             1142 non-null   object \n",
      " 9   Country                                    1142 non-null   object \n",
      " 10  Year                                       489 non-null    float64\n",
      " 11  Area of Specialization/Research Interests  623 non-null    object \n",
      " 12  Other Information                          124 non-null    object \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 116.1+ KB\n"
     ]
    }
   ],
   "source": [
    "professors.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-perth",
   "metadata": {},
   "source": [
    "The focus will be on the non-null 'Country' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mediterranean-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Germany', ' New Zealand', ' Sweden', ' USA', 'Australia',\n",
       "       'Austria', 'Canada', 'China', 'Finland', 'France', 'Greece',\n",
       "       'HongKong', 'Ireland', 'Italy', 'Japan', 'Macau', 'Malaysia',\n",
       "       'Mauritius', 'Netherland', 'New Zealand', 'Norway', 'Pakistan',\n",
       "       'Portugal', 'Russian Federation', 'Saudi Arabia', 'Scotland',\n",
       "       'Singapore', 'South Korea', 'SouthKorea', 'Spain', 'Sweden',\n",
       "       'Thailand', 'Turkey', 'UK', 'USA', 'USofA', 'Urbana', 'germany'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Country' unique values\n",
    "countries = professors['Country'].unique()\n",
    "\n",
    "# sort them alphabetically\n",
    "countries.sort()\n",
    "\n",
    "# take a look\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sustained-corps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 38 unique listed values in 'Country'\n",
    "len(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-trinidad",
   "metadata": {},
   "source": [
    "## Basic cleaning to improve consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-insured",
   "metadata": {},
   "source": [
    "### White spaces and uppercase letter\n",
    "\n",
    " As seen in 'countries', extra white spaces and/or uppercase letters result in some countries appearing twice. Using:\n",
    " - str.lower( ) will lowercase all strings, and \n",
    " - str.strip( ) will remove extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "overhead-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "professors['Country'] = professors['Country'].str.lower()\n",
    "\n",
    "# remove trailing white spaces\n",
    "professors['Country'] = professors['Country'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-economy",
   "metadata": {},
   "source": [
    "Another look at 'Country' unique values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interim-breeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['australia', 'austria', 'canada', 'china', 'finland', 'france',\n",
       "       'germany', 'greece', 'hongkong', 'ireland', 'italy', 'japan',\n",
       "       'macau', 'malaysia', 'mauritius', 'netherland', 'new zealand',\n",
       "       'norway', 'pakistan', 'portugal', 'russian federation',\n",
       "       'saudi arabia', 'scotland', 'singapore', 'south korea',\n",
       "       'southkorea', 'spain', 'sweden', 'thailand', 'turkey', 'uk',\n",
       "       'urbana', 'usa', 'usofa'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Country' unique values\n",
    "countries = professors['Country'].unique()\n",
    "\n",
    "# sort them alphabetically\n",
    "countries.sort()\n",
    "\n",
    "# take a look\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aging-posting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from 38 -> 34: some duplicates were eliminated\n",
    "len(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-favorite",
   "metadata": {},
   "source": [
    "### \"urbana\"\n",
    "\n",
    "What is 'urbana'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beginning-actor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S#</th>\n",
       "      <th>Teacher Name</th>\n",
       "      <th>University Currently Teaching</th>\n",
       "      <th>Department</th>\n",
       "      <th>Province University Located</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Terminal Degree</th>\n",
       "      <th>Graduated from</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Area of Specialization/Research Interests</th>\n",
       "      <th>Other Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>384</td>\n",
       "      <td>385</td>\n",
       "      <td>Sheikh Muhammad Qasim</td>\n",
       "      <td>Air University</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Capital</td>\n",
       "      <td>Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>University of Illinois</td>\n",
       "      <td>urbana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   S#           Teacher Name University Currently Teaching  \\\n",
       "161         384  385  Sheikh Muhammad Qasim                Air University   \n",
       "\n",
       "           Department Province University Located Designation Terminal Degree  \\\n",
       "161  Computer Science                     Capital   Professor             PhD   \n",
       "\n",
       "             Graduated from Country  Year  \\\n",
       "161  University of Illinois  urbana   NaN   \n",
       "\n",
       "    Area of Specialization/Research Interests Other Information  \n",
       "161                                       NaN               NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professors[professors['Country'] == 'urbana']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-qatar",
   "metadata": {},
   "source": [
    "According to the info describing the dataset: https://www.kaggle.com/zusmani/pakistanintellectualcapitalcs\n",
    "\n",
    "\"The dataset contains list of computer science/IT professors from 89 different universities of Pakistan.\n",
    "\n",
    "Variables:\n",
    "\n",
    "The dataset contains Serial No, Teacherâ€™s Name, University Currently Teaching, Department, Province University Located, Designation, Terminal Degree, Graduated from (university for professor), Country of graduation, Year, Area of Specialization/Research Interests, and some Other Information\"\n",
    "\n",
    "The University of Illinois is in 'usa', so I'll make the change for this professor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expensive-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "professors.loc[professors['Country'] == 'urbana'] = 'usa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "foreign-necklace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['australia', 'austria', 'canada', 'china', 'finland', 'france',\n",
       "       'germany', 'greece', 'hongkong', 'ireland', 'italy', 'japan',\n",
       "       'macau', 'malaysia', 'mauritius', 'netherland', 'new zealand',\n",
       "       'norway', 'pakistan', 'portugal', 'russian federation',\n",
       "       'saudi arabia', 'scotland', 'singapore', 'south korea',\n",
       "       'southkorea', 'spain', 'sweden', 'thailand', 'turkey', 'uk', 'usa',\n",
       "       'usofa'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = professors['Country'].unique()\n",
    "countries.sort()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "listed-upgrade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from 34 -> 33\n",
    "len(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-liver",
   "metadata": {},
   "source": [
    "## Using FuzzyWuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-lexington",
   "metadata": {},
   "source": [
    "Basic cleaning has solved almost all data inconsistencies. But there are enough similarities in two pairs of countries to suggest they probably refer to one country, each:\n",
    "- south korea: 'south korea' and 'southkorea'\n",
    "- usa: 'usa'and 'usofa'\n",
    "\n",
    "FuzzyWuzzy to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expected-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FuzzyWuzzy pattern matching tools\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-culture",
   "metadata": {},
   "source": [
    "Instead of just correcting by hand, FuzzyWuzzy can automate the cleaning.\n",
    "\n",
    "In computer science, the formal term for fuzzy string search is called \"Approximate string matching\". This technique finds strings that approximately match the target pattern. The less changes needed to transform a string to the target string, the closer it is to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chronic-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(process.extract())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-field",
   "metadata": {},
   "source": [
    "Looking at found at help(process.extract( )):\n",
    "    \n",
    "    \n",
    "- query: the desired target string\n",
    "\n",
    "- choices: an iterable or dictionary-like object containing choices to compare to the target string; in this case it is \"countries\", the sorted unique values in the 'Country' column.\n",
    "\n",
    "- scorer: Optional function for scoring matches between the query and\n",
    "        an individual processed choice. This should be a function\n",
    "        of the form f(query, choice) -> int.\n",
    "        By default, fuzz.WRatio() is used and expects both query and\n",
    "        choice to be strings.        \n",
    "I specified fuzz.token_sort_ratio\n",
    "\n",
    "\n",
    "- limit = maximum elements to be returned; in this case, I specified the default 5\n",
    "\n",
    "\n",
    "FuzzyWuzzy returns a ratio of the distance between two strings. The closer the ratio is to 100, the smaller the edit distance between the two strings. Here, we're going to find the top five strings from our list of unique countries that have the closest distance to our target string.\n",
    "\n",
    "process.extract( ) outputs a list of tuples of the found match and its score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-adelaide",
   "metadata": {},
   "source": [
    "### South Korea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "junior-barrel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('south korea', 100),\n",
       " ('southkorea', 48),\n",
       " ('saudi arabia', 43),\n",
       " ('norway', 35),\n",
       " ('austria', 33)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the top 5 closest matches to \"south korea\"\n",
    "matches_KR = process.extract(query=\"south korea\",\n",
    "                             choices=countries,\n",
    "                             scorer=fuzz.token_sort_ratio,\n",
    "                             limit=5)\n",
    "\n",
    "# take a look at the matches for \"south korea\"\n",
    "matches_KR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-cleaner",
   "metadata": {},
   "source": [
    "Of course, 'south korea' gets a score of 100, as it is exactly the same string specified in the 'query' argument. The string 'southkorea' has a score of 48, in terms of matching with the target. The other matches don't seem relevant.\n",
    "\n",
    "To automate the change to the desired target, a function can be used.  \n",
    "\n",
    "I modified the function provided in the Kaggle lesson to make it more generic to be able to use it for 'usa', an extra step that was not covered. I did this by adding the 'min_ratio' parameter. I also created a detailed docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "strange-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_matches_in_column(df, column, string_to_match, min_ratio):\n",
    "    '''\n",
    "    A function that takes outputted strings and scores of process.extract()\n",
    "    and changes them to the specified string_to_match,\n",
    "    when the fuzz.token_sort_ratio is equal or higher than the specified min_ratio.\n",
    "    \n",
    "    Parameters:\n",
    "    df: dataframe name\n",
    "    column(str): specify the df column\n",
    "    string_to_match(str): the desired target string to match\n",
    "    min_ratio(int): the minimum score from process.extract scorer required to be affected by the change\n",
    "    \n",
    "    Returns:\n",
    "    print statement \"All done!\" once the changes have been completed.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    # get the top 5 closest matches to our input string\n",
    "    matches = process.extract(string_to_match,\n",
    "                              strings,\n",
    "                              limit=5,\n",
    "                              scorer=fuzz.token_sort_ratio)\n",
    "\n",
    "    # only get matches with a specified min_ratio\n",
    "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
    "\n",
    "    # get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match\n",
    "    \n",
    "    # let us know the function's done\n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-poultry",
   "metadata": {},
   "source": [
    "Let's see the function in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sixth-richardson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# replace close matches to \"south korea\" with \"south korea\"\n",
    "# I chose min_ratio=47, because that was the min_ratio threshold that had best matches in matches_KR\n",
    "replace_matches_in_column(df=professors,\n",
    "                          column='Country',\n",
    "                          string_to_match=\"south korea\",\n",
    "                          min_ratio=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "velvet-format",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['australia', 'austria', 'canada', 'china', 'finland', 'france',\n",
       "       'germany', 'greece', 'hongkong', 'ireland', 'italy', 'japan',\n",
       "       'macau', 'malaysia', 'mauritius', 'netherland', 'new zealand',\n",
       "       'norway', 'pakistan', 'portugal', 'russian federation',\n",
       "       'saudi arabia', 'scotland', 'singapore', 'south korea', 'spain',\n",
       "       'sweden', 'thailand', 'turkey', 'uk', 'usa', 'usofa'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'Country' column\n",
    "countries = professors['Country'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "countries.sort()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "plain-mobility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from 33 -> 32\n",
    "len(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-macro",
   "metadata": {},
   "source": [
    "### United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "married-richmond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('usa', 100),\n",
       " ('usofa', 75),\n",
       " ('austria', 60),\n",
       " ('australia', 50),\n",
       " ('spain', 50)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the top 5 closest matches to \"usa\"\n",
    "matches_US = process.extract(query=\"usa\",\n",
    "                             choices=countries,\n",
    "                             scorer=fuzz.token_sort_ratio,\n",
    "                             limit=5)\n",
    "\n",
    "# take a look at the matches for \"usa\"\n",
    "matches_US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-pavilion",
   "metadata": {},
   "source": [
    "Of course, 'usa' gets a score of 100, as it is exactly the same string specified in the 'query' argument. The string 'usofa' has a score of 75, in terms of matching with the target. The other matches don't seem relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "southwest-nylon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# replace close matches to \"usa\" with \"usa\"\n",
    "# I chose min_ratio=75, because that was the min_ratio threshold that had best matches in matches_US\n",
    "replace_matches_in_column(df=professors,\n",
    "                          column='Country',\n",
    "                          string_to_match=\"usa\",\n",
    "                          min_ratio=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "stupid-angle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['australia', 'austria', 'canada', 'china', 'finland', 'france',\n",
       "       'germany', 'greece', 'hongkong', 'ireland', 'italy', 'japan',\n",
       "       'macau', 'malaysia', 'mauritius', 'netherland', 'new zealand',\n",
       "       'norway', 'pakistan', 'portugal', 'russian federation',\n",
       "       'saudi arabia', 'scotland', 'singapore', 'south korea', 'spain',\n",
       "       'sweden', 'thailand', 'turkey', 'uk', 'usa'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'Country' column\n",
    "countries = professors['Country'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "countries.sort()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "prescribed-island",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from 32 -> 31 unique values\n",
    "len(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-estonia",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-casting",
   "metadata": {},
   "source": [
    "### chardet\n",
    "The lesson imports included import chardet. As far as I could determine, it wasn't needed in this example. However, I still decided to look it up and found some interesting pages:\n",
    "- chardet documentation at https://chardet.readthedocs.io/en/latest/ \n",
    "- The research paper \"A composite approach to language/encoding detection\" which led to the Mozilla implementation at https://www-archive.mozilla.org/projects/intl/universalcharsetdetection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-monthly",
   "metadata": {},
   "source": [
    "### 'choices' in process.extract( )\n",
    "\n",
    "In this example, the unique values of the 'Country' column was used as the 'choices' argument in process.extract( ). Knowing that there are standard country code lists and dictionaries, means process.extract can become quite powerful as an efficient way to standardize inconsistent data entry for countries and many more values with standards strings already set.\n",
    "\n",
    "I really enjoyed learning how to use FuzzyWuzzy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-annual",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
